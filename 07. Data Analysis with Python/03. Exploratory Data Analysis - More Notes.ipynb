{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - More Notes\n",
    "\n",
    "## Correlation\n",
    "We can quantify the strength of the correlation between 2 features through:\n",
    "- Pearson correlation coefficient\n",
    "- P-value\n",
    "\n",
    "The scipy stats package can be used to retrieve both values, e.g. \n",
    "\n",
    "`pearson_coef, p_value = stats.pearsonr(df['horsepower'], df['price'])`\n",
    "\n",
    "will find the correlation between horsepower and price for the df dataframe.\n",
    "\n",
    "### Pearson Correlation Coefficient\n",
    "- Close to +1 : Large Positive relationship\n",
    "- Close to -1 : Large Negative relationship\n",
    "- Close to 0 : No relationship\n",
    "\n",
    "### P-value\n",
    "- P-value < 0.001 : Strong certainty in the result\n",
    "- P-value < 0.05 : Moderate certainty in the result\n",
    "- P-value < 0.1 : Weak certainty in the result\n",
    "- P-value > 0.1 : No certainty in the result\n",
    "\n",
    "### Strong Correlations\n",
    "A strong correlation occurs when the Pearson correlation coefficient is close to 1 or -1 (positive or negative relationship), and when the P-value is less than 0.001."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Square Test for Association ($\\chi^2$)\n",
    "\n",
    "When dealing with the relationships between two categorical variables, we canâ€™t use the same correlation method for continuous variables, we will have to employ the use of chi square test for the association. The Chi-square test is intended to test how likely it is that an observed distribution is due to chance. It measures how well the observed distribution of data fits with the distribution that is expected if the variables are independent.\n",
    "\n",
    "The Chi-square tests null hypothesis is that the variables are independent. The test compares the observed data to the values that the model expects if the data was distributed in different categories by chance. Anytime the observed data doesn't fit within the model of the expected values, the probability that the variables are dependent becomes stronger, thus proving the null hypothesis incorrect. The Chi-square does not tell you the type of relationship that exists between both variables only that a relationship exists.\n",
    "\n",
    "To generate this in Python, use the chi square contingency function in the scipy.stats package:\n",
    "\n",
    "`scipy.stats.chi2_contingency(cont_table, correction=True)`\n",
    "\n",
    "The function will print out the chi-square test value, the p-value, and a degree of freedom. For details, google the package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
